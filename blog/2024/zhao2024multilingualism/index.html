<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> MWork | Prasoon Bajpai </title> <meta name="author" content="Prasoon Bajpai"> <meta name="description" content="How do Large Language Models Handle Multilingualism?"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://prasoon1207.github.io/blog/2024/zhao2024multilingualism/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Prasoon</span> Bajpai </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">MWork</h1> <p class="post-meta"> Created in August 31, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/paper"> <i class="fa-solid fa-hashtag fa-sm"></i> paper</a>   <a href="/blog/tag/multilingualism"> <i class="fa-solid fa-hashtag fa-sm"></i> multilingualism</a>   ·   <a href="/blog/category/papers"> <i class="fa-solid fa-tag fa-sm"></i> papers</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <div style="text-align: center;"> <img src="/assets/papers/zhao2024multilingualism/header.png" alt="paper_header"> </div> <p><br><br></p> <p>In this work, the authors introduce a new framework for explaining the property of multilingualism in Multilingual Large Language Models (MLLMs). How do we define this property of ‘Multilingualism’? The property of multilingualism enables MLLMs to text in multiple languages. In this paper, the authors have introduced a framework they call <strong>MWork</strong> which states that MLLMs first convert queries to a unified representation. They reason on this unified representation with multilingual knowledge extraction and finally, they translate queries to the target language.</p> <ol> <li> <p>Conversion to a <em>unified representation</em> - <br> The authors state that the first step in handling non-English queries is to convert them to English in the initial layers of MLLMs. According to Hou et al., 2023, attention mechanisms are utilized in reasoning over a text corpus. The authors observe a decrease in the number of <em>non-English</em> neurons (?) of the attention matrices in the middle layers of the MLLMs. <em>Can reasoning be performed over text in a language other than English?</em> It is unlikely owing to the decline in the number of non-English neurons in the reasoning (attention structures) regions of MLLMs.</p> </li> <li> <p>Task-Solving - <br> <em>What about the neurons in the FFN layers?</em> - The authors observe NO decrease in the number of language-specific neurons in FFN structures across all layers of MLLMs. Hence, the authors decompose the task-solving into two steps: <em>thinking</em> in English and <em>extracting knowledge</em> multilingually from language-specific neurons in the middle layers of MLLMs.</p> </li> <li> <p>Generation of output - <br>- <strong>MWork</strong> proposes that models <em>generate</em> responses by translating back to the query’s original language. <em>At this stage, one can think of a simple verifying experiment for this step</em>. Suppose we have a query in two non-English languages say, French and Urdu. Consider a query requiring extraction of a knowledge point prevalently common in both French and Urdu literature. <em>Will there be an inconsistency in MLLM performance?</em> (Maybe we can intercept the residual embeddings to see the checkpoint of back-translation initiation for languages structurally dissimilar to English.)</p> </li> </ol> <p><strong>How will I verify it?</strong></p> <p>I will look at each of the three steps separately: <em>conversion</em> to unified English representation, <em>task-solving</em> and <em>translation</em>. <strong><em>Conversion</em></strong> -&gt; Relative amount of English / non-English tokens; <em>Does the converted representation still relate to the original query? (Can we quantify it?) &lt;- Credits to Eshaan Tanwar from LCS2 for suggesting this.</em> 2. <strong><em>Task-Solving</em> MLWork</strong> claims that knowledge is extracted from language-specific neurons in the FFN structures. <em>Does deactivating these neurons affect the performance?</em> ALSO, is the knowledge diffused into different languages or localized to the language of the pretraining text? <em>Consider a setup when some knowledge is only limited to Vietnamese literature. Does deactivating neurons of FFN of Vietnamese completely downgrade MLLM performance?</em><br><br><br> Is there a way to identify neurons relating to some knowledge?<br> How much overlap do they have with language-specific neurons?<br><br><br> <em><strong>Translation</strong></em> -&gt; I will certainly want to look at works trying to mechanistically interpret translation in MLLMs. (Is there a gap here?). Using those, one can design experiments to test this. <br> The authors found that “<em>deactivating randomly sampled neurons in the task-solving layers disables the capabilities of LLMs in reasoning to a greater extent than deactivating randomly sampled neurons in all layers</em>”. This proves that the middle layers are associated with <em>thinking</em> + <em>extracting knowledge</em> (basically <em>task-solving</em>). (Note the authors refer to these <em>middle</em> layers of MLLMs as the <em>task-solving</em> layer.) <br><br> <strong>How to verify separation of <em>thinking in English</em> and <em>extracting knowledge multilingually?</em></strong> <br><br></p> <ul> <li>I would have created a synthetic task that does not involve any nuanced knowledge extraction (<em>Commonsense reasoning</em> over multiple languages). Taking some non-English languages under study : <strong>(1)</strong> Deactivate these language-specific neurons in the FFN structures of the <em>task-solving</em> layer. (Since I am not sure if knowledge from one language gets leaked into other language-specific neurons of FFN, let me propose all of these language-specific neurons of FFN) <strong>(2)</strong> Compare the performance of MLLMs with and without deactivation. Moreover, deactivating language-specific neurons of the attention structures in the <em>task-solving</em> layer should not have much effect on non-English queries as compared to English queries.</li> <li>The authors also claim that <em>deactivating language-specific neurons within the feed-forward structure of the task-solving layer predominantly affects non-English languages</em>. This implies that processing multilingual queries necessitates accessing the multilingual information embedded within the relevant structures.<br><br> </li> </ul> <p><strong>How to verify the translation/generation structure of MWork</strong>- The authors have deactivated language-specific neurons in the final layers of the MLLMs and commented on a decline in performance. As I mentioned earlier, there can be ways to selectively comment on the nature of translation happening at this stage. The authors have further shown that selectively fine-tuning the parameters in the language-specific neurons enhances the performance of MLLMs for queries in that language. <br> <strong>Questions for further research -</strong></p> <ul> <li>Polyglots are shown to process native languages at much greater ease as compared to other languages, even at the same level of proficiency. Given we declare it as the native language for the LLMs, can we quantify if being subjective to pre-training in multilingual corpora, affects the <em>ease</em> of handling English queries? (Let the setting be purely reasoning-based and let <em>ease</em> be quantified as the number of neurons activated in the task-solving layer.</li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/Future/">Future</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Prasoon Bajpai. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-9VCZGHDCZH"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-9VCZGHDCZH");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-cv",title:"cv",description:"Please also refer to the CV (pdf) attached to the pdf document iconography on the right.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-future",title:"Future",description:"How I feel about this.",section:"Posts",handler:()=>{window.location.href="/blog/2024/Future/"}},{id:"post-mwork",title:"MWork",description:"How do Large Language Models Handle Multilingualism?",section:"Posts",handler:()=>{window.location.href="/blog/2024/zhao2024multilingualism/"}},{id:"news-presented-my-poster-at-emnlp-2024",title:"Presented my poster at EMNLP 2024.",description:"",section:"News"},{id:"news-presented-my-poster-at-emnlp-2024",title:"Presented my poster at EMNLP 2024.",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%70%72%61%73%6F%6F%6E%62%61%6A%70%61%69%37%38%36@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=NmHOvbIAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Prasoon1207","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/prasoon-bajpai-51835519b","_blank")}},{id:"socials-instagram",title:"Instagram",section:"Socials",handler:()=>{window.open("https://instagram.com/_zorpsoon","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>