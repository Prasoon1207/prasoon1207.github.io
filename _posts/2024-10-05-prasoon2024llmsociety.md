---
title: llmsociety
layout: post
date: 2024-10-05 15:09:00
description: Modelling human intelligence with a community of LLMs.
tags: opinion
featured: true
---

<div style="text-align: center;">
    <img src="/assets/img/llmsociety/marvin_minsky.jpg" alt="Marvin Minsky" width="300" height="300">
</div>

<br>


I often consider myself lucky (and blessed) to have gotten to approach computational language modelling and its subsidiaries after taking all relevant linguisitcs courses offered by the Humanities Department at IIT Delhi. I remember myself getting deeply intrigued about the impact of language understanding in shaping the intellect of new-born babies and how human intelligence (which manifests to intelligence and theorems) got accelerated by collaboration enabled using complex language symbols. When I met people who explained to me first, the task of **next word prediction** using deep learning, I found myself comfortably positioned to harness my knowledge and deep internal ambition to **modelling human intelligence**. This blog is just the projection of my initial thoughts on this idea and I have gathered the required confidence to translate my ambition to a workable project after going through papers listed in the _References_ subsection below.

<br>


<div style="text-align: center;">
    <img src="/assets/img/llmsociety/psychmodelhumanintel.png" alt="a psychological model of human intelligence" width="500" height="300">
</div>

<br>


In our efforts to model human intelligence, we should take a great deal of motivation from the foundational psychological discourses (like _Society Of Minds_ from Marvin Minsky). My personal recipe of convenient computational modelling of human intelligence assumes that all human intelligence is basically a community of human minds, that itself is composed of like-minded/ group experts of human beings. There are channels of communication between these sub-communities of human minds (or society of agents as I like to call them). There are also ways in which these agents communicate with each other, they discuss a domain-specific problem (_let there be interpretability!_), reach a consensus and forward their decision/reasoning to other communities.

<br>
**Where does LLM come in?**

<div style="text-align: center;">
    <img src="/assets/img/llmsociety/deepmodelhumanintel.png" alt="a deep net model of human intelligence" width="500" height="300">
</div>
<br>
Replacing these individual human minds / agents with LLMs seems the way to go. Thinking from first principles, a human mind is a more general computational unit. Similarly, this model is not focussing on creating *expert LLMs* but sort of *expert LLM communities*.
<br>

**What are some open problems that I would like to tackle?**

- Profiling of LLMs/ Communities of LLMs: Is it possible to create an automatic metric to measure human-like characteristics of LLMs, such as 'overconfident', 'humour' etc.
- Dynamic Communication: Most of the literature today, focussing on multi-model multi-agent collaborations, uses hard prompts to make LLMs communicate with each other. Can we use a specialized **clan community** of models to create soft prompts that enable better communication, if any.


**References**

- ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs
- MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for Reasoning
- Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View
- Society of Minds
