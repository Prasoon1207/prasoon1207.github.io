---
layout: about
title: about
permalink: /

profile:
  align: right
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular

news: false # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

<!--
<br>
_Hold your head up high_,<br>
_For at the end of the storm,_<br>
_There is a golden sky._<br>
CC: <a href = 'https://www.youtube.com/watch?v=xx0Ru_1zPVk'>YNWA</a>
<br><br><br><br>
-->

<a href = 'https://www.youtube.com/watch?v=rEq1Z0bjdw'> Hello There </a> <br>

I graduated from IIT-D on August 10, 2024, with a dual degree in Maths & Computing. During my last two years there, I worked as a graduate researcher under <a href = 'https://tanmoychak.com/'>Prof. Tanmoy Chaktraborty</a> in the <a href = 'lcs2.in'>Laboratory for Computational Social Sciences</a>. 
My primary research interest lies in the interpretation of the internal mechanisms of LLMs through mathematical modelling. I am also interested in the scope of selectively editing model architecture to enhance and explain emergent behaviours at varied parameter scales. I want to explore the applicability of multimodal LLMs as formal reasoning engines and interpret their fused modality spaces to better guide their scaling methodologies. I also wish to design dynamic and high-bandwidth _thought_ data structures to explain the internal reasoning mechanisms of LLMs, irrespective of the modality present in the query. These can be used to create an internal fine-grained reasoning evaluation framework, not focusing entirely on datasets and tasks. 

The invention of language enabled effective communication channels for receiving feedback and spreading knowledge. The understanding of language has been closely linked with other neural activities in humans. I have always been intrigued by biology and I am highly interested in adopting principles of biological evolution to expand the capabilities of LLMs. For example, the act of foraging enables ant colonies to skip redundant learning phases by acquiring information from already knowledgeable ants. Using this lens, one can hope to improve the intrinsic architecture of the Mixture-Of-Experts methodology. Given a fixed budget of parameter space, an attempt should be made to design more nuanced communication networks between smaller language models to reason effectively as a team, instead of each component being a reserved expert.

Apart from mathing and coding, I cycle and do a little bit of graphite sketching.<br>


<!--
My research interests primarily lie in explaining the behaviour of modern LLMs through mechanistic interpretation and establishing parallels between the biological think-tank (yes, the _squishy brain_) and modern architectures for language modelling. I am working on some cool problems as a quantitative model researcher at <a href = 'wellsfargo.com'>Wells Fargo</a>. The opportunity to re-learn <a href = 'https://www.math.uchicago.edu/~lawler/finbook.pdf'> math </a> fundamentals is surely refreshing. (But my heart still lies inside a neural net). <br>
-->


<!--
I also follow Chelsea F.C. and am an active <a href = 'https://fantasy.premierleague.com/entry/7736456/history'> FPL </a> player.<br>
Do message me at any of my contact points if you want to talk about NLP, <a href = 'https://www.youtube.com/watch?v=9XIuBCFNBFw'> Progressive Rock</a> or <a href = 'https://www.youtube.com/watch?v=sJQ_QvNGhHc'>The Big Bang Theory</a>.
-->


<!--Put your address / P.O. box / other info right below your picture. You can also disable any of these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.-->

<!--Link to your social media connections, too. This theme is set up to use [Font Awesome icons](https://fontawesome.com/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them.-->

